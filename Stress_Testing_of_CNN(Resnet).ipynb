{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OcGoXvuumYBx"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision import datasets, transforms, models\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_0RfG3CunRj8",
        "outputId": "1a0b64fe-f77d-4e4c-aa44-f363fed59ed3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "# Fixed seed: report this value\n",
        "SEED = 42\n",
        "\n",
        "def set_seed(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "set_seed(SEED)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A6bSvKBYnYL9"
      },
      "outputs": [],
      "source": [
        "# CIFAR-10 normalization stats\n",
        "cifar10_mean = (0.4914, 0.4822, 0.4465)\n",
        "cifar10_std  = (0.2470, 0.2435, 0.2616)\n",
        "\n",
        "# Baseline transforms (no augmentation)\n",
        "train_transform_baseline = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(cifar10_mean, cifar10_std),\n",
        "])\n",
        "\n",
        "# Augmented transforms: used only in the \"constrained modification\" experiment\n",
        "train_transform_aug = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(cifar10_mean, cifar10_std),\n",
        "])\n",
        "\n",
        "# Test/validation transforms (no augmentation)\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(cifar10_mean, cifar10_std),\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YyEtnHFunbmf"
      },
      "outputs": [],
      "source": [
        "def get_cifar10_loaders(batch_size=128, use_augmentation=False, val_size=5000):\n",
        "    transform_train = train_transform_aug if use_augmentation else train_transform_baseline\n",
        "\n",
        "    full_train = datasets.CIFAR10(root=\"./data\", train=True, download=True,\n",
        "                                  transform=transform_train)\n",
        "    subset_size = 25000\n",
        "    full_train, _ = random_split(full_train, [subset_size, len(full_train) - subset_size], generator=torch.Generator().manual_seed(SEED))\n",
        "\n",
        "    test_set = datasets.CIFAR10(root=\"./data\", train=False, download=True,\n",
        "                                transform=test_transform)\n",
        "\n",
        "    train_size = len(full_train) - val_size\n",
        "    train_set, val_set = random_split(full_train, [train_size, val_size],\n",
        "                                      generator=torch.Generator().manual_seed(SEED))\n",
        "\n",
        "    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "    val_loader   = DataLoader(val_set,   batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "    test_loader  = DataLoader(test_set,  batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "    return train_loader, val_loader, test_loader\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p_aUr8hgngnT"
      },
      "outputs": [],
      "source": [
        "def get_resnet18_cifar10():\n",
        "    model = models.resnet18(weights=None)  # no pretrained weights\n",
        "    num_ftrs = model.fc.in_features\n",
        "    model.fc = nn.Linear(num_ftrs, 10)\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7vYfelyKnkwK"
      },
      "outputs": [],
      "source": [
        "def train_one_epoch(model, loader, criterion, optimizer, device):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for images, labels in loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "        _, preds = outputs.max(1)\n",
        "        correct += preds.eq(labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "    epoch_loss = running_loss / total\n",
        "    epoch_acc = correct / total\n",
        "    return epoch_loss, epoch_acc\n",
        "\n",
        "\n",
        "def evaluate(model, loader, criterion, device):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            running_loss += loss.item() * images.size(0)\n",
        "            _, preds = outputs.max(1)\n",
        "            correct += preds.eq(labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "    epoch_loss = running_loss / total\n",
        "    epoch_acc = correct / total\n",
        "    return epoch_loss, epoch_acc\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a_CspZPWnoYN"
      },
      "outputs": [],
      "source": [
        "def run_experiment(use_augmentation=False, num_epochs=20, lr=0.1):\n",
        "    train_loader, val_loader, test_loader = get_cifar10_loaders(\n",
        "        batch_size=128,\n",
        "        use_augmentation=use_augmentation\n",
        "    )\n",
        "\n",
        "    model = get_resnet18_cifar10().to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=5e-4)\n",
        "\n",
        "    train_losses, val_losses = [], []\n",
        "    train_accs, val_accs = [], []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        train_loss, train_acc = train_one_epoch(model, train_loader, criterion, optimizer, device)\n",
        "        val_loss, val_acc = evaluate(model, val_loader, criterion, device)\n",
        "\n",
        "        train_losses.append(train_loss)\n",
        "        val_losses.append(val_loss)\n",
        "        train_accs.append(train_acc)\n",
        "        val_accs.append(val_acc)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs} \"\n",
        "              f\"Train Loss: {train_loss:.4f} Acc: {train_acc:.4f} \"\n",
        "              f\"Val Loss: {val_loss:.4f} Acc: {val_acc:.4f}\")\n",
        "\n",
        "    # Final test accuracy\n",
        "    test_loss, test_acc = evaluate(model, test_loader, criterion, device)\n",
        "    print(f\"Test Loss: {test_loss:.4f} | Test Acc: {test_acc:.4f}\")\n",
        "\n",
        "    history = {\n",
        "        \"train_losses\": train_losses,\n",
        "        \"val_losses\": val_losses,\n",
        "        \"train_accs\": train_accs,\n",
        "        \"val_accs\": val_accs,\n",
        "        \"test_loss\": test_loss,\n",
        "        \"test_acc\": test_acc,\n",
        "    }\n",
        "    return model, (train_loader, val_loader, test_loader), history\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F5QRd2-mnxto",
        "outputId": "d0b01649-cc26-4c09-d3f1-eabdb40d8d33"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40 Train Loss: 2.4057 Acc: 0.2953 Val Loss: 2.0627 Acc: 0.3786\n",
            "Epoch 2/40 Train Loss: 1.6115 Acc: 0.4239 Val Loss: 1.7415 Acc: 0.4236\n",
            "Epoch 3/40 Train Loss: 1.3904 Acc: 0.4965 Val Loss: 1.4196 Acc: 0.4810\n",
            "Epoch 4/40 Train Loss: 1.2432 Acc: 0.5546 Val Loss: 1.2564 Acc: 0.5574\n",
            "Epoch 5/40 Train Loss: 1.1181 Acc: 0.5990 Val Loss: 1.1660 Acc: 0.5836\n",
            "Epoch 6/40 Train Loss: 1.0042 Acc: 0.6459 Val Loss: 1.1680 Acc: 0.5880\n",
            "Epoch 7/40 Train Loss: 0.9100 Acc: 0.6780 Val Loss: 1.1261 Acc: 0.6012\n",
            "Epoch 8/40 Train Loss: 0.8047 Acc: 0.7154 Val Loss: 1.0403 Acc: 0.6338\n",
            "Epoch 9/40 Train Loss: 0.7303 Acc: 0.7427 Val Loss: 1.1251 Acc: 0.6274\n",
            "Epoch 10/40 Train Loss: 0.6584 Acc: 0.7700 Val Loss: 1.0772 Acc: 0.6266\n",
            "Epoch 11/40 Train Loss: 0.5795 Acc: 0.7968 Val Loss: 1.0654 Acc: 0.6410\n",
            "Epoch 12/40 Train Loss: 0.5352 Acc: 0.8133 Val Loss: 1.0753 Acc: 0.6504\n",
            "Epoch 13/40 Train Loss: 0.4759 Acc: 0.8356 Val Loss: 1.2172 Acc: 0.6390\n",
            "Epoch 14/40 Train Loss: 0.4504 Acc: 0.8447 Val Loss: 1.2179 Acc: 0.6420\n",
            "Epoch 15/40 Train Loss: 0.4036 Acc: 0.8595 Val Loss: 1.2429 Acc: 0.6322\n",
            "Epoch 16/40 Train Loss: 0.3774 Acc: 0.8677 Val Loss: 1.2110 Acc: 0.6510\n",
            "Epoch 17/40 Train Loss: 0.3411 Acc: 0.8826 Val Loss: 1.2488 Acc: 0.6526\n",
            "Epoch 18/40 Train Loss: 0.3305 Acc: 0.8886 Val Loss: 1.3442 Acc: 0.6342\n",
            "Epoch 19/40 Train Loss: 0.3019 Acc: 0.8960 Val Loss: 1.4076 Acc: 0.6332\n",
            "Epoch 20/40 Train Loss: 0.2970 Acc: 0.8976 Val Loss: 1.2416 Acc: 0.6542\n",
            "Epoch 21/40 Train Loss: 0.2416 Acc: 0.9176 Val Loss: 1.3044 Acc: 0.6662\n",
            "Epoch 22/40 Train Loss: 0.2704 Acc: 0.9075 Val Loss: 1.2981 Acc: 0.6502\n",
            "Epoch 23/40 Train Loss: 0.2498 Acc: 0.9137 Val Loss: 1.2928 Acc: 0.6566\n",
            "Epoch 24/40 Train Loss: 0.2340 Acc: 0.9188 Val Loss: 1.3437 Acc: 0.6450\n",
            "Epoch 25/40 Train Loss: 0.2448 Acc: 0.9183 Val Loss: 1.3358 Acc: 0.6490\n",
            "Epoch 26/40 Train Loss: 0.2236 Acc: 0.9218 Val Loss: 1.5106 Acc: 0.6334\n",
            "Epoch 27/40 Train Loss: 0.2291 Acc: 0.9212 Val Loss: 1.3375 Acc: 0.6474\n",
            "Epoch 28/40 Train Loss: 0.2137 Acc: 0.9276 Val Loss: 1.2960 Acc: 0.6586\n",
            "Epoch 29/40 Train Loss: 0.2162 Acc: 0.9253 Val Loss: 1.5144 Acc: 0.6236\n",
            "Epoch 30/40 Train Loss: 0.2224 Acc: 0.9238 Val Loss: 1.3360 Acc: 0.6548\n",
            "Epoch 31/40 Train Loss: 0.2226 Acc: 0.9238 Val Loss: 1.2556 Acc: 0.6652\n",
            "Epoch 32/40 Train Loss: 0.1868 Acc: 0.9370 Val Loss: 1.4813 Acc: 0.6388\n",
            "Epoch 33/40 Train Loss: 0.2056 Acc: 0.9313 Val Loss: 1.3083 Acc: 0.6646\n",
            "Epoch 34/40 Train Loss: 0.2004 Acc: 0.9335 Val Loss: 1.3941 Acc: 0.6578\n",
            "Epoch 35/40 Train Loss: 0.1919 Acc: 0.9322 Val Loss: 1.5487 Acc: 0.6344\n",
            "Epoch 36/40 Train Loss: 0.2106 Acc: 0.9286 Val Loss: 1.3456 Acc: 0.6600\n",
            "Epoch 37/40 Train Loss: 0.1933 Acc: 0.9345 Val Loss: 1.3676 Acc: 0.6584\n",
            "Epoch 38/40 Train Loss: 0.1868 Acc: 0.9365 Val Loss: 1.4672 Acc: 0.6396\n",
            "Epoch 39/40 Train Loss: 0.2217 Acc: 0.9256 Val Loss: 1.3947 Acc: 0.6512\n",
            "Epoch 40/40 Train Loss: 0.1886 Acc: 0.9358 Val Loss: 1.4933 Acc: 0.6498\n",
            "Test Loss: 1.5290 | Test Acc: 0.6403\n",
            "Epoch 1/40 Train Loss: 2.6195 Acc: 0.2185 Val Loss: 2.6275 Acc: 0.2562\n",
            "Epoch 2/40 Train Loss: 1.8717 Acc: 0.3122 Val Loss: 1.7088 Acc: 0.3488\n",
            "Epoch 3/40 Train Loss: 1.6628 Acc: 0.3845 Val Loss: 1.5781 Acc: 0.4102\n",
            "Epoch 4/40 Train Loss: 1.5577 Acc: 0.4268 Val Loss: 1.5921 Acc: 0.4080\n",
            "Epoch 5/40 Train Loss: 1.4749 Acc: 0.4590 Val Loss: 1.4532 Acc: 0.4666\n",
            "Epoch 6/40 Train Loss: 1.3918 Acc: 0.4928 Val Loss: 1.4990 Acc: 0.4558\n",
            "Epoch 7/40 Train Loss: 1.3267 Acc: 0.5199 Val Loss: 1.4110 Acc: 0.4830\n",
            "Epoch 8/40 Train Loss: 1.2622 Acc: 0.5436 Val Loss: 1.3003 Acc: 0.5310\n",
            "Epoch 9/40 Train Loss: 1.1934 Acc: 0.5713 Val Loss: 1.2216 Acc: 0.5644\n",
            "Epoch 10/40 Train Loss: 1.1405 Acc: 0.5939 Val Loss: 1.1506 Acc: 0.5870\n",
            "Epoch 11/40 Train Loss: 1.0774 Acc: 0.6157 Val Loss: 1.1061 Acc: 0.6092\n",
            "Epoch 12/40 Train Loss: 1.0492 Acc: 0.6241 Val Loss: 1.1026 Acc: 0.6138\n",
            "Epoch 13/40 Train Loss: 1.0141 Acc: 0.6431 Val Loss: 1.0677 Acc: 0.6244\n",
            "Epoch 14/40 Train Loss: 0.9831 Acc: 0.6514 Val Loss: 1.1698 Acc: 0.5960\n",
            "Epoch 15/40 Train Loss: 0.9528 Acc: 0.6696 Val Loss: 1.0058 Acc: 0.6458\n",
            "Epoch 16/40 Train Loss: 0.9229 Acc: 0.6762 Val Loss: 1.0028 Acc: 0.6456\n",
            "Epoch 17/40 Train Loss: 0.9172 Acc: 0.6797 Val Loss: 0.9992 Acc: 0.6524\n",
            "Epoch 18/40 Train Loss: 0.8926 Acc: 0.6938 Val Loss: 0.9766 Acc: 0.6588\n",
            "Epoch 19/40 Train Loss: 0.8702 Acc: 0.6996 Val Loss: 1.0494 Acc: 0.6344\n",
            "Epoch 20/40 Train Loss: 0.8580 Acc: 0.7012 Val Loss: 0.9996 Acc: 0.6502\n",
            "Epoch 21/40 Train Loss: 0.8410 Acc: 0.7084 Val Loss: 0.9941 Acc: 0.6590\n",
            "Epoch 22/40 Train Loss: 0.8132 Acc: 0.7144 Val Loss: 0.9609 Acc: 0.6714\n",
            "Epoch 23/40 Train Loss: 0.8130 Acc: 0.7182 Val Loss: 1.1154 Acc: 0.6380\n",
            "Epoch 24/40 Train Loss: 0.7947 Acc: 0.7232 Val Loss: 1.1022 Acc: 0.6570\n",
            "Epoch 25/40 Train Loss: 0.7882 Acc: 0.7262 Val Loss: 1.0389 Acc: 0.6424\n",
            "Epoch 26/40 Train Loss: 0.7935 Acc: 0.7245 Val Loss: 1.0680 Acc: 0.6504\n",
            "Epoch 27/40 Train Loss: 0.7694 Acc: 0.7322 Val Loss: 0.9952 Acc: 0.6656\n",
            "Epoch 28/40 Train Loss: 0.7596 Acc: 0.7390 Val Loss: 0.9105 Acc: 0.6842\n",
            "Epoch 29/40 Train Loss: 0.7599 Acc: 0.7383 Val Loss: 0.9358 Acc: 0.6820\n",
            "Epoch 30/40 Train Loss: 0.7523 Acc: 0.7381 Val Loss: 1.0175 Acc: 0.6744\n",
            "Epoch 31/40 Train Loss: 0.7384 Acc: 0.7466 Val Loss: 0.9765 Acc: 0.6722\n",
            "Epoch 32/40 Train Loss: 0.7291 Acc: 0.7484 Val Loss: 0.9443 Acc: 0.6778\n",
            "Epoch 33/40 Train Loss: 0.7349 Acc: 0.7444 Val Loss: 0.9565 Acc: 0.6796\n",
            "Epoch 34/40 Train Loss: 0.7132 Acc: 0.7530 Val Loss: 0.9010 Acc: 0.6960\n",
            "Epoch 35/40 Train Loss: 0.7060 Acc: 0.7553 Val Loss: 1.0272 Acc: 0.6540\n",
            "Epoch 36/40 Train Loss: 0.7187 Acc: 0.7546 Val Loss: 0.8829 Acc: 0.7004\n",
            "Epoch 37/40 Train Loss: 0.7090 Acc: 0.7565 Val Loss: 0.9547 Acc: 0.6774\n",
            "Epoch 38/40 Train Loss: 0.6894 Acc: 0.7633 Val Loss: 0.9245 Acc: 0.6768\n",
            "Epoch 39/40 Train Loss: 0.6860 Acc: 0.7637 Val Loss: 0.8765 Acc: 0.7050\n",
            "Epoch 40/40 Train Loss: 0.6827 Acc: 0.7667 Val Loss: 0.8385 Acc: 0.7106\n",
            "Test Loss: 0.7996 | Test Acc: 0.7253\n"
          ]
        }
      ],
      "source": [
        "# Baseline (no augmentation)\n",
        "baseline_model, baseline_loaders, baseline_hist = run_experiment(\n",
        "    use_augmentation=False, num_epochs=40, lr=0.1\n",
        ")\n",
        "\n",
        "# Constrained modification (with augmentation)\n",
        "aug_model, aug_loaders, aug_hist = run_experiment(\n",
        "    use_augmentation=True, num_epochs=40, lr=0.1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rRoUEfqOn_1O"
      },
      "outputs": [],
      "source": [
        "classes = ('airplane', 'automobile', 'bird', 'cat', 'deer',\n",
        "           'dog', 'frog', 'horse', 'ship', 'truck')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_failure_cases(model, loader, device, max_cases=1000):\n",
        "    model.eval()\n",
        "    failure_cases = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            logits = model(images)\n",
        "            probs = F.softmax(logits, dim=1)\n",
        "            confs, preds = probs.max(dim=1)\n",
        "\n",
        "            mismatches = preds.ne(labels)\n",
        "            if mismatches.any():\n",
        "                for i in torch.where(mismatches)[0]:\n",
        "                    failure_cases.append({\n",
        "                        \"image\": images[i].cpu(),        # normalized tensor\n",
        "                        \"label\": labels[i].item(),\n",
        "                        \"pred\": preds[i].item(),\n",
        "                        \"conf\": confs[i].item(),\n",
        "                        \"probs\": probs[i].cpu(),\n",
        "                    })\n",
        "            if len(failure_cases) >= max_cases:\n",
        "                break\n",
        "\n",
        "    # Sort by confidence descending\n",
        "    failure_cases.sort(key=lambda x: x[\"conf\"], reverse=True)\n",
        "    return failure_cases\n"
      ],
      "metadata": {
        "id": "O1NxNzOSgbz0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_, _, test_loader = baseline_loaders\n",
        "baseline_failures = get_failure_cases(baseline_model, test_loader, device, max_cases=500)\n",
        "\n",
        "print(f\"Collected {len(baseline_failures)} failure cases.\")\n",
        "for i in range(3):\n",
        "    fc = baseline_failures[i]\n",
        "    print(i,\n",
        "          \"True:\", classes[fc[\"label\"]],\n",
        "          \"Pred:\", classes[fc[\"pred\"]],\n",
        "          f\"Conf: {fc['conf']:.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rEl6cPmvgsWI",
        "outputId": "23b66014-323f-40ae-f7a7-1154b6d164e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collected 506 failure cases.\n",
            "0 True: ship Pred: airplane Conf: 1.000\n",
            "1 True: bird Pred: dog Conf: 1.000\n",
            "2 True: ship Pred: airplane Conf: 1.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class GradCAM:\n",
        "    def __init__(self, model, target_layer):\n",
        "        self.model = model\n",
        "        self.model.eval()\n",
        "        self.target_layer = target_layer\n",
        "\n",
        "        self.activations = None\n",
        "        self.gradients = None\n",
        "\n",
        "        def forward_hook(module, inp, out):\n",
        "            self.activations = out.detach()\n",
        "\n",
        "        def backward_hook(module, grad_in, grad_out):\n",
        "            self.gradients = grad_out[0].detach()\n",
        "\n",
        "        self.fwd_handle = target_layer.register_forward_hook(forward_hook)\n",
        "        self.bwd_handle = target_layer.register_backward_hook(backward_hook)\n",
        "\n",
        "    def __call__(self, x, target_class=None):\n",
        "        self.model.zero_grad()\n",
        "        out = self.model(x)\n",
        "\n",
        "        if target_class is None:\n",
        "            target_class = out.argmax(dim=1)\n",
        "\n",
        "        # For batch, we do class-wise gradient\n",
        "        loss = out[torch.arange(x.size(0)), target_class]\n",
        "        loss.backward(torch.ones_like(loss))\n",
        "\n",
        "        grads = self.gradients  # [B, C, H, W]\n",
        "        activations = self.activations  # [B, C, H, W]\n",
        "\n",
        "        weights = grads.mean(dim=(2, 3), keepdim=True)  # [B, C, 1, 1]\n",
        "        cam = (weights * activations).sum(dim=1, keepdim=True)  # [B, 1, H, W]\n",
        "        cam = F.relu(cam)\n",
        "\n",
        "        # Normalize CAM to [0,1] per image\n",
        "        B, _, H, W = cam.size()\n",
        "        cam = cam.view(B, -1)\n",
        "        cam_min, cam_max = cam.min(dim=1, keepdim=True).values, cam.max(dim=1, keepdim=True).values\n",
        "        cam = (cam - cam_min) / (cam_max - cam_min + 1e-8)\n",
        "        cam = cam.view(B, 1, H, W)\n",
        "\n",
        "        return cam\n",
        "\n",
        "    def close(self):\n",
        "        self.fwd_handle.remove()\n",
        "        self.bwd_handle.remove()\n"
      ],
      "metadata": {
        "id": "MrmCA_NFg2Dw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: create Grad-CAM object for baseline model\n",
        "target_layer = baseline_model.layer4[-1].conv2\n",
        "gradcam_baseline = GradCAM(baseline_model, target_layer)\n"
      ],
      "metadata": {
        "id": "eta3lMlag5b1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def denormalize(img_tensor):\n",
        "    # img_tensor: [3, H, W], normalized\n",
        "    mean = torch.tensor(cifar10_mean).view(3, 1, 1)\n",
        "    std = torch.tensor(cifar10_std).view(3, 1, 1)\n",
        "    img = img_tensor * std + mean\n",
        "    img = torch.clamp(img, 0, 1)\n",
        "    return img\n",
        "\n",
        "def show_gradcam_on_image(img_tensor, cam_tensor, alpha=0.5):\n",
        "    \"\"\"\n",
        "    img_tensor: [3, H, W] (normalized)\n",
        "    cam_tensor: [1, Hc, Wc] (values in [0,1], upsample to H,W)\n",
        "    \"\"\"\n",
        "    img = denormalize(img_tensor).permute(1, 2, 0).numpy()  # H,W,3\n",
        "    cam = cam_tensor.squeeze(0).cpu().numpy()               # Hc,Wc\n",
        "\n",
        "    # Resize CAM to image size\n",
        "    cam = torch.tensor(cam).unsqueeze(0).unsqueeze(0)\n",
        "    cam = F.interpolate(cam, size=img.shape[:2], mode=\"bilinear\", align_corners=False)\n",
        "    cam = cam.squeeze().numpy()\n",
        "\n",
        "    heatmap = plt.get_cmap(\"jet\")(cam)[:, :, :3]  # drop alpha\n",
        "    overlay = alpha * heatmap + (1 - alpha) * img\n",
        "    overlay = np.clip(overlay, 0, 1)\n",
        "\n",
        "    plt.figure(figsize=(6, 3))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.imshow(img)\n",
        "    plt.axis(\"off\")\n",
        "    plt.title(\"Original\")\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.imshow(overlay)\n",
        "    plt.axis(\"off\")\n",
        "    plt.title(\"Grad-CAM\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "_ZLSb5k2g_fm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pick one failure case from baseline_failures\n",
        "fc = baseline_failures[0]\n",
        "img = fc[\"image\"].unsqueeze(0).to(device)  # [1,3,32,32]\n",
        "\n",
        "with torch.no_grad():\n",
        "    pred = baseline_model(img).argmax(dim=1).item()\n",
        "\n",
        "cam = gradcam_baseline(img, target_class=torch.tensor([pred]).to(device))\n",
        "show_gradcam_on_image(fc[\"image\"], cam[0].cpu())\n",
        "\n",
        "print(\"True:\", classes[fc[\"label\"]],\n",
        "      \"Pred:\", classes[fc[\"pred\"]],\n",
        "      f\"Conf: {fc['conf']:.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388
        },
        "id": "0oB1kjDOgvRC",
        "outputId": "c3592635-c4d6-46a9-cb29-cda1e47069a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:1866: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x300 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True: ship Pred: airplane Conf: 1.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target_layer_aug = aug_model.layer4[-1].conv2\n",
        "gradcam_aug = GradCAM(aug_model, target_layer_aug)\n"
      ],
      "metadata": {
        "id": "eR3lHAanhFcV"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}